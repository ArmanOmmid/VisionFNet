python3 /content/repository/src/run_experiment.py --experiment_path experiments --experiment_name gft_m gft_m -D datasets --download

==== Start Main ====
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/CIFAR10/train/cifar-10-python.tar.gz
Extracting datasets/CIFAR10/train/cifar-10-python.tar.gz to datasets/CIFAR10/train
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/CIFAR10/test/cifar-10-python.tar.gz
Extracting datasets/CIFAR10/test/cifar-10-python.tar.gz to datasets/CIFAR10/test
Dataset: CIFAR10
{'train': 41666, 'val': 8334, 'test': 10000}
Model Architecture:  fvit_monolith
Class weights: tensor([0.9999, 1.0001, 1.0001, 0.9999, 1.0001, 0.9999, 1.0001, 0.9999, 0.9999,
        0.9999], dtype=torch.float64)
============================================================================================================================================================================================================================
Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable
============================================================================================================================================================================================================================
VisionTransformer                             [8, 3, 32, 32]            [8, 10]                   --                             --                   --                        --                        True
├─ModuleList: 1-1                             --                        --                        --                             --                   --                        --                        True
│    └─Conv2d: 2-1                            [8, 3, 32, 32]            [8, 64, 16, 16]           832                         0.19%                   [2, 2]                    1,703,936                 True
│    └─Conv2d: 2-2                            [8, 3, 32, 32]            [8, 64, 8, 8]             3,136                       0.73%                   [4, 4]                    1,605,632                 True
│    └─Conv2d: 2-3                            [8, 3, 32, 32]            [8, 64, 4, 4]             12,352                      2.86%                   [8, 8]                    1,581,056                 True
│    └─Conv2d: 2-4                            [8, 3, 32, 32]            [8, 64, 2, 2]             49,216                     11.41%                   [16, 16]                  1,574,912                 True
├─Encoder: 1-2                                [8, 340, 64]              [8, 340, 64]              21,760                      5.05%                   --                        --                        True
│    └─Dropout: 2-5                           [8, 340, 64]              [8, 340, 64]              --                             --                   --                        --                        --
│    └─Sequential: 2-6                        [8, 340, 64]              [8, 340, 64]              --                             --                   --                        --                        True
│    │    └─SpectralBlock: 3-1                [8, 340, 64]              [8, 340, 64]              58,944                     13.67%                   --                        3,011,072                 True
│    │    └─SpectralBlock: 3-2                [8, 340, 64]              [8, 340, 64]              58,944                     13.67%                   --                        3,011,072                 True
│    │    └─SpectralBlock: 3-3                [8, 340, 64]              [8, 340, 64]              58,944                     13.67%                   --                        3,011,072                 True
│    │    └─SpectralBlock: 3-4                [8, 340, 64]              [8, 340, 64]              58,944                     13.67%                   --                        3,011,072                 True
│    │    └─AttentionBlock: 3-5               [8, 340, 64]              [8, 340, 64]              49,984                     11.59%                   --                        266,752                   True
│    │    └─AttentionBlock: 3-6               [8, 340, 64]              [8, 340, 64]              49,984                     11.59%                   --                        266,752                   True
│    └─LayerNorm: 2-7                         [8, 340, 64]              [8, 340, 64]              128                         0.03%                   --                        1,024                     True
├─Conv1d: 1-3                                 [8, 340, 64]              [8, 18, 64]               6,138                       1.42%                   [1]                       3,142,656                 True
├─MLP: 1-4                                    [8, 18, 64]               [8, 18, 8]                --                             --                   --                        --                        True
│    └─Linear: 2-8                            [8, 18, 64]               [8, 18, 8]                520                         0.12%                   --                        4,160                     True
│    └─Dropout: 2-9                           [8, 18, 8]                [8, 18, 8]                --                             --                   --                        --                        --
├─Sequential: 1-5                             [8, 144]                  [8, 10]                   --                             --                   --                        --                        True
│    └─Linear: 2-10                           [8, 144]                  [8, 10]                   1,450                       0.34%                   --                        11,600                    True
============================================================================================================================================================================================================================
Total params: 431,276
Trainable params: 431,276
Non-trainable params: 0
Total mult-adds (M): 22.20
============================================================================================================================================================================================================================
Input size (MB): 0.10
Forward/backward pass size (MB): 67.91
Params size (MB): 1.50
Estimated Total Size (MB): 69.52
============================================================================================================================================================================================================================
Initializing Experiments
Training

--------------------
Epoch 1 / 50
--------------------
Learning Rate: 0.0001
Epoch 1 | Time Elapsed: 118.28256464004517 |
                      Train | Accuracy: 0.4333 | Loss: 1.5453
                 Validation | Accuracy: 0.5066 | Loss: 1.3780

--------------------
Epoch 2 / 50
--------------------
Learning Rate: 9.990133642141359e-05
Epoch 2 | Time Elapsed: 116.60748434066772 |
                      Train | Accuracy: 0.5598 | Loss: 1.2205
                 Validation | Accuracy: 0.5679 | Loss: 1.2019

--------------------
Epoch 3 / 50
--------------------
Learning Rate: 9.96057350657239e-05
Epoch 3 | Time Elapsed: 117.60881543159485 |
                      Train | Accuracy: 0.6179 | Loss: 1.0677
                 Validation | Accuracy: 0.5943 | Loss: 1.1569

--------------------
Epoch 4 / 50
--------------------
Learning Rate: 9.911436253643444e-05
Epoch 4 | Time Elapsed: 117.4382495880127 |
                      Train | Accuracy: 0.6647 | Loss: 0.9405
                 Validation | Accuracy: 0.5924 | Loss: 1.1833

--------------------
Epoch 5 / 50
--------------------
Learning Rate: 9.842915805643155e-05
Epoch 5 | Time Elapsed: 117.71885323524475 |
                      Train | Accuracy: 0.7092 | Loss: 0.8193
                 Validation | Accuracy: 0.5883 | Loss: 1.2106

--------------------
Epoch 6 / 50
--------------------
Learning Rate: 9.755282581475769e-05
Epoch 6 | Time Elapsed: 117.67547750473022 |
                      Train | Accuracy: 0.7512 | Loss: 0.6996
                 Validation | Accuracy: 0.5884 | Loss: 1.2546

--------------------
Epoch 7 / 50
--------------------
Learning Rate: 9.648882429441257e-05
Epoch 7 | Time Elapsed: 115.99861431121826 |
                      Train | Accuracy: 0.7944 | Loss: 0.5818
                 Validation | Accuracy: 0.5910 | Loss: 1.3778

--------------------
Epoch 8 / 50
--------------------
Learning Rate: 9.524135262330098e-05
Epoch 8 | Time Elapsed: 115.26274681091309 |
                      Train | Accuracy: 0.8291 | Loss: 0.4800
                 Validation | Accuracy: 0.5763 | Loss: 1.4619

--------------------
Epoch 9 / 50
--------------------
Learning Rate: 9.381533400219317e-05
Epoch 9 | Time Elapsed: 116.0977714061737 |
                      Train | Accuracy: 0.8616 | Loss: 0.3859
                 Validation | Accuracy: 0.5631 | Loss: 1.6477

--------------------
Epoch 10 / 50
--------------------
Learning Rate: 9.221639627510075e-05
Epoch 10 | Time Elapsed: 115.25601744651794 |
                      Train | Accuracy: 0.8873 | Loss: 0.3151
                 Validation | Accuracy: 0.5628 | Loss: 1.8280

--------------------
Epoch 11 / 50
--------------------
Learning Rate: 9.045084971874735e-05
Epoch 11 | Time Elapsed: 115.00774788856506 |
                      Train | Accuracy: 0.9070 | Loss: 0.2606
                 Validation | Accuracy: 0.5655 | Loss: 1.9594

--------------------
Epoch 12 / 50
--------------------
Learning Rate: 8.852566213878945e-05
Epoch 12 | Time Elapsed: 114.32867193222046 |
                      Train | Accuracy: 0.9213 | Loss: 0.2230
                 Validation | Accuracy: 0.5596 | Loss: 2.0727

--------------------
Epoch 13 / 50
--------------------
Learning Rate: 8.644843137107056e-05
Epoch 13 | Time Elapsed: 114.80325388908386 |
                      Train | Accuracy: 0.9323 | Loss: 0.1902
                 Validation | Accuracy: 0.5599 | Loss: 2.1950

--------------------
Epoch 14 / 50
--------------------
Learning Rate: 8.422735529643442e-05
Epoch 14 | Time Elapsed: 115.43622303009033 |
                      Train | Accuracy: 0.9414 | Loss: 0.1663
                 Validation | Accuracy: 0.5673 | Loss: 2.2783

--------------------
Epoch 15 / 50
--------------------
Learning Rate: 8.187119948743447e-05
Epoch 15 | Time Elapsed: 116.20968461036682 |
                      Train | Accuracy: 0.9499 | Loss: 0.1425
                 Validation | Accuracy: 0.5580 | Loss: 2.4240

--------------------
Epoch 16 / 50
--------------------
Learning Rate: 7.938926261462366e-05
Epoch 16 | Time Elapsed: 116.21334624290466 |
                      Train | Accuracy: 0.9575 | Loss: 0.1203
                 Validation | Accuracy: 0.5637 | Loss: 2.4864

--------------------
Epoch 17 / 50
--------------------
Learning Rate: 7.679133974894982e-05
Epoch 17 | Time Elapsed: 116.06882810592651 |
                      Train | Accuracy: 0.9602 | Loss: 0.1119
                 Validation | Accuracy: 0.5617 | Loss: 2.5682

--------------------
Epoch 18 / 50
--------------------
Learning Rate: 7.408768370508575e-05
Epoch 18 | Time Elapsed: 115.86920237541199 |
                      Train | Accuracy: 0.9662 | Loss: 0.0992
                 Validation | Accuracy: 0.5613 | Loss: 2.6805

--------------------
Epoch 19 / 50
--------------------
Learning Rate: 7.128896457825361e-05
Epoch 19 | Time Elapsed: 115.98000383377075 |
                      Train | Accuracy: 0.9690 | Loss: 0.0876
                 Validation | Accuracy: 0.5598 | Loss: 2.7306

--------------------
Epoch 20 / 50
--------------------
Learning Rate: 6.840622763423389e-05
Epoch 20 | Time Elapsed: 116.0250871181488 |
                      Train | Accuracy: 0.9732 | Loss: 0.0788
                 Validation | Accuracy: 0.5614 | Loss: 2.8408

--------------------
Epoch 21 / 50
--------------------
Learning Rate: 6.545084971874736e-05
Epoch 21 | Time Elapsed: 116.47129154205322 |
                      Train | Accuracy: 0.9766 | Loss: 0.0679
                 Validation | Accuracy: 0.5691 | Loss: 2.9025

--------------------
Epoch 22 / 50
--------------------
Learning Rate: 6.243449435824272e-05
Epoch 22 | Time Elapsed: 117.43171405792236 |
                      Train | Accuracy: 0.9792 | Loss: 0.0610
                 Validation | Accuracy: 0.5665 | Loss: 2.9198

--------------------
Epoch 23 / 50
--------------------
Learning Rate: 5.9369065729286224e-05
Epoch 23 | Time Elapsed: 115.8769896030426 |
                      Train | Accuracy: 0.9820 | Loss: 0.0534
                 Validation | Accuracy: 0.5618 | Loss: 2.9869

--------------------
Epoch 24 / 50
--------------------
Learning Rate: 5.626666167821521e-05
Epoch 24 | Time Elapsed: 116.75303316116333 |
                      Train | Accuracy: 0.9841 | Loss: 0.0475
                 Validation | Accuracy: 0.5728 | Loss: 3.0059
Early Stopping...
Best IoU score: None
--------------------
Test Loss 1.1318624942302704
Test Accuracy 0.5921000000000001
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 229376/170498071 [00:00<01:31, 1852790.67it/s]  1%|▏         | 2490368/170498071 [00:00<00:12, 12960310.42it/s]  6%|▌         | 10452992/170498071 [00:00<00:03, 41840585.31it/s] 11%|█▏        | 19496960/170498071 [00:00<00:02, 60035865.94it/s] 17%|█▋        | 28999680/170498071 [00:00<00:01, 71728222.31it/s] 23%|██▎       | 38469632/170498071 [00:00<00:01, 79331161.63it/s] 27%|██▋       | 46497792/170498071 [00:00<00:01, 78466258.57it/s] 32%|███▏      | 54427648/170498071 [00:00<00:01, 72857596.67it/s] 36%|███▋      | 61833216/170498071 [00:00<00:01, 69920407.90it/s] 42%|████▏     | 71008256/170498071 [00:01<00:01, 76125911.96it/s] 47%|████▋     | 79888384/170498071 [00:01<00:01, 79774712.32it/s] 52%|█████▏    | 88899584/170498071 [00:01<00:00, 82739352.68it/s] 57%|█████▋    | 97255424/170498071 [00:01<00:00, 78582348.73it/s] 62%|██████▏   | 106201088/170498071 [00:01<00:00, 81641386.71it/s] 67%|██████▋   | 115048448/170498071 [00:01<00:00, 83558657.66it/s] 73%|███████▎  | 123994112/170498071 [00:01<00:00, 84991156.80it/s] 78%|███████▊  | 133267456/170498071 [00:01<00:00, 87234642.75it/s] 83%|████████▎ | 142114816/170498071 [00:01<00:00, 87576943.80it/s] 89%|████████▊ | 151158784/170498071 [00:01<00:00, 88057687.68it/s] 94%|█████████▍| 160595968/170498071 [00:02<00:00, 89931703.13it/s] 99%|█████████▉| 169607168/170498071 [00:02<00:00, 89641022.52it/s]100%|██████████| 170498071/170498071 [00:02<00:00, 77096588.65it/s]
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 229376/170498071 [00:00<01:35, 1778431.35it/s]  1%|          | 2031616/170498071 [00:00<00:16, 10314892.67it/s]  5%|▍         | 7864320/170498071 [00:00<00:05, 30875084.05it/s]  8%|▊         | 13729792/170498071 [00:00<00:03, 41208931.86it/s] 12%|█▏        | 19628032/170498071 [00:00<00:03, 47342032.70it/s] 15%|█▍        | 25559040/170498071 [00:00<00:02, 51197971.07it/s] 18%|█▊        | 31457280/170498071 [00:00<00:02, 53594633.36it/s] 22%|██▏       | 37388288/170498071 [00:00<00:02, 55268987.44it/s] 25%|██▌       | 43220992/170498071 [00:00<00:02, 56172098.63it/s] 29%|██▉       | 49020928/170498071 [00:01<00:02, 56677007.38it/s] 32%|███▏      | 54722560/170498071 [00:01<00:02, 56658766.27it/s] 35%|███▌      | 60424192/170498071 [00:01<00:02, 50919662.76it/s] 38%|███▊      | 65634304/170498071 [00:01<00:02, 46786728.05it/s] 41%|████▏     | 70451200/170498071 [00:01<00:02, 44434879.56it/s] 44%|████▍     | 75005952/170498071 [00:01<00:02, 42729158.46it/s] 47%|████▋     | 79364096/170498071 [00:01<00:02, 41688096.66it/s] 49%|████▉     | 83591168/170498071 [00:01<00:02, 40942990.07it/s] 51%|█████▏    | 87719936/170498071 [00:01<00:02, 40322608.96it/s] 54%|█████▍    | 91783168/170498071 [00:02<00:01, 39945430.09it/s] 56%|█████▌    | 95813632/170498071 [00:02<00:01, 39588399.86it/s] 59%|█████▊    | 99778560/170498071 [00:02<00:01, 39119148.91it/s] 61%|██████    | 103710720/170498071 [00:02<00:01, 38511380.74it/s] 63%|██████▎   | 107577344/170498071 [00:02<00:01, 38197186.14it/s] 65%|██████▌   | 111411200/170498071 [00:02<00:01, 37903428.04it/s] 68%|██████▊   | 115212288/170498071 [00:02<00:01, 37621245.65it/s] 70%|██████▉   | 118980608/170498071 [00:02<00:01, 37359072.94it/s] 72%|███████▏  | 122716160/170498071 [00:02<00:01, 37211326.39it/s] 74%|███████▍  | 126550016/170498071 [00:03<00:01, 37523989.29it/s] 77%|███████▋  | 130482176/170498071 [00:03<00:01, 37915346.47it/s] 79%|███████▉  | 134447104/170498071 [00:03<00:00, 38338453.25it/s] 81%|████████  | 138346496/170498071 [00:03<00:00, 38451632.49it/s] 83%|████████▎ | 142245888/170498071 [00:03<00:00, 38594307.24it/s] 86%|████████▌ | 146178048/170498071 [00:03<00:00, 38796682.76it/s] 88%|████████▊ | 150110208/170498071 [00:03<00:00, 38808546.75it/s] 90%|█████████ | 154075136/170498071 [00:03<00:00, 38940732.65it/s] 93%|█████████▎| 158007296/170498071 [00:03<00:00, 39040817.89it/s] 95%|█████████▍| 161939456/170498071 [00:03<00:00, 38980866.96it/s] 97%|█████████▋| 165838848/170498071 [00:04<00:00, 38861749.99it/s]100%|█████████▉| 169771008/170498071 [00:04<00:00, 38997041.70it/s]100%|██████████| 170498071/170498071 [00:04<00:00, 41265649.08it/s]
