python3 /content/repository/src/run_experiment.py --experiment_path experiments --experiment_name test1 fno_m -D datasets --download

==== Start Main ====
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/CIFAR10/train/cifar-10-python.tar.gz
Extracting datasets/CIFAR10/train/cifar-10-python.tar.gz to datasets/CIFAR10/train
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/CIFAR10/test/cifar-10-python.tar.gz
Extracting datasets/CIFAR10/test/cifar-10-python.tar.gz to datasets/CIFAR10/test
Dataset: CIFAR10
{'train': 41666, 'val': 8334, 'test': 10000}
Model Architecture:  fvit_monolith
Class weights: tensor([0.9999, 0.9999, 1.0001, 0.9999, 0.9999, 1.0001, 1.0001, 1.0001, 0.9999,
        0.9999], dtype=torch.float64)
============================================================================================================================================================================================================================
Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable
============================================================================================================================================================================================================================
VisionTransformer                             [8, 3, 32, 32]            [8, 10]                   --                             --                   --                        --                        True
├─ModuleList: 1-1                             --                        --                        --                             --                   --                        --                        True
│    └─Conv2d: 2-1                            [8, 3, 32, 32]            [8, 64, 16, 16]           832                         0.01%                   [2, 2]                    1,703,936                 True
│    └─Conv2d: 2-2                            [8, 3, 32, 32]            [8, 64, 8, 8]             3,136                       0.05%                   [4, 4]                    1,605,632                 True
│    └─Conv2d: 2-3                            [8, 3, 32, 32]            [8, 64, 4, 4]             12,352                      0.18%                   [8, 8]                    1,581,056                 True
│    └─Conv2d: 2-4                            [8, 3, 32, 32]            [8, 64, 2, 2]             49,216                      0.72%                   [16, 16]                  1,574,912                 True
├─Encoder: 1-2                                [8, 340, 64]              [8, 340, 64]              21,760                      0.32%                   --                        --                        True
│    └─Dropout: 2-5                           [8, 340, 64]              [8, 340, 64]              --                             --                   --                        --                        --
│    └─Sequential: 2-6                        [8, 340, 64]              [8, 340, 64]              --                             --                   --                        --                        True
│    │    └─SpectralBlock: 3-1                [8, 340, 64]              [8, 340, 64]              1,671,744                  24.29%                   --                        175,903,232               True
│    │    └─SpectralBlock: 3-2                [8, 340, 64]              [8, 340, 64]              1,671,744                  24.29%                   --                        175,903,232               True
│    │    └─SpectralBlock: 3-3                [8, 340, 64]              [8, 340, 64]              1,671,744                  24.29%                   --                        175,903,232               True
│    │    └─SpectralBlock: 3-4                [8, 340, 64]              [8, 340, 64]              1,671,744                  24.29%                   --                        175,903,232               True
│    │    └─AttentionBlock: 3-5               [8, 340, 64]              [8, 340, 64]              49,984                      0.73%                   --                        266,752                   True
│    │    └─AttentionBlock: 3-6               [8, 340, 64]              [8, 340, 64]              49,984                      0.73%                   --                        266,752                   True
│    └─LayerNorm: 2-7                         [8, 340, 64]              [8, 340, 64]              128                         0.00%                   --                        1,024                     True
├─Conv1d: 1-3                                 [8, 340, 64]              [8, 18, 64]               6,138                       0.09%                   [1]                       3,142,656                 True
├─MLP: 1-4                                    [8, 18, 64]               [8, 18, 8]                --                             --                   --                        --                        True
│    └─Linear: 2-8                            [8, 18, 64]               [8, 18, 8]                520                         0.01%                   --                        4,160                     True
│    └─Dropout: 2-9                           [8, 18, 8]                [8, 18, 8]                --                             --                   --                        --                        --
├─Sequential: 1-5                             [8, 144]                  [8, 10]                   --                             --                   --                        --                        True
│    └─Linear: 2-10                           [8, 144]                  [8, 10]                   1,450                       0.02%                   --                        11,600                    True
============================================================================================================================================================================================================================
Total params: 6,882,476
Trainable params: 6,882,476
Non-trainable params: 0
Total mult-adds (M): 713.77
============================================================================================================================================================================================================================
Input size (MB): 0.10
Forward/backward pass size (MB): 67.91
Params size (MB): 27.31
Estimated Total Size (MB): 95.32
============================================================================================================================================================================================================================
Initializing Experiments
Training

--------------------
Epoch 1 / 50
--------------------
Learning Rate: 0.0001
Epoch 1 | Time Elapsed: 142.01524209976196 |
                      Train | Accuracy: 0.4575 | Loss: 1.4851
                 Validation | Accuracy: 0.5272 | Loss: 1.2979

--------------------
Epoch 2 / 50
--------------------
Learning Rate: 9.990133642141359e-05
Epoch 2 | Time Elapsed: 141.77536582946777 |
                      Train | Accuracy: 0.5724 | Loss: 1.1925
                 Validation | Accuracy: 0.5798 | Loss: 1.1825

--------------------
Epoch 3 / 50
--------------------
Learning Rate: 9.96057350657239e-05
Epoch 3 | Time Elapsed: 142.51914358139038 |
                      Train | Accuracy: 0.6213 | Loss: 1.0602
                 Validation | Accuracy: 0.5965 | Loss: 1.1318

--------------------
Epoch 4 / 50
--------------------
Learning Rate: 9.911436253643444e-05
Epoch 4 | Time Elapsed: 142.7391152381897 |
                      Train | Accuracy: 0.6565 | Loss: 0.9709
                 Validation | Accuracy: 0.6112 | Loss: 1.1030

--------------------
Epoch 5 / 50
--------------------
Learning Rate: 9.842915805643155e-05
Epoch 5 | Time Elapsed: 140.78162240982056 |
                      Train | Accuracy: 0.6856 | Loss: 0.8932
                 Validation | Accuracy: 0.6284 | Loss: 1.0534

--------------------
Epoch 6 / 50
--------------------
Learning Rate: 9.755282581475769e-05
Epoch 6 | Time Elapsed: 142.67762923240662 |
                      Train | Accuracy: 0.7099 | Loss: 0.8260
                 Validation | Accuracy: 0.6220 | Loss: 1.0866

--------------------
Epoch 7 / 50
--------------------
Learning Rate: 9.648882429441257e-05
Epoch 7 | Time Elapsed: 141.9680335521698 |
                      Train | Accuracy: 0.7311 | Loss: 0.7675
                 Validation | Accuracy: 0.6295 | Loss: 1.0644

--------------------
Epoch 8 / 50
--------------------
Learning Rate: 9.524135262330098e-05
Epoch 8 | Time Elapsed: 143.6116042137146 |
                      Train | Accuracy: 0.7502 | Loss: 0.7039
                 Validation | Accuracy: 0.6309 | Loss: 1.0874

--------------------
Epoch 9 / 50
--------------------
Learning Rate: 9.381533400219317e-05
Epoch 9 | Time Elapsed: 142.8640923500061 |
                      Train | Accuracy: 0.7727 | Loss: 0.6414
                 Validation | Accuracy: 0.6328 | Loss: 1.1246

--------------------
Epoch 10 / 50
--------------------
Learning Rate: 9.221639627510075e-05
Epoch 10 | Time Elapsed: 141.9131636619568 |
                      Train | Accuracy: 0.7953 | Loss: 0.5840
                 Validation | Accuracy: 0.6290 | Loss: 1.1398

--------------------
Epoch 11 / 50
--------------------
Learning Rate: 9.045084971874735e-05
Epoch 11 | Time Elapsed: 142.79957556724548 |
                      Train | Accuracy: 0.8149 | Loss: 0.5218
                 Validation | Accuracy: 0.6278 | Loss: 1.2051

--------------------
Epoch 12 / 50
--------------------
Learning Rate: 8.852566213878945e-05
Epoch 12 | Time Elapsed: 141.81491589546204 |
                      Train | Accuracy: 0.8345 | Loss: 0.4690
                 Validation | Accuracy: 0.6263 | Loss: 1.2522

--------------------
Epoch 13 / 50
--------------------
Learning Rate: 8.644843137107056e-05
Epoch 13 | Time Elapsed: 142.4556007385254 |
                      Train | Accuracy: 0.8525 | Loss: 0.4196
                 Validation | Accuracy: 0.6250 | Loss: 1.3313

--------------------
Epoch 14 / 50
--------------------
Learning Rate: 8.422735529643442e-05
Epoch 14 | Time Elapsed: 141.51703929901123 |
                      Train | Accuracy: 0.8664 | Loss: 0.3767
                 Validation | Accuracy: 0.6234 | Loss: 1.3793

--------------------
Epoch 15 / 50
--------------------
Learning Rate: 8.187119948743447e-05
Epoch 15 | Time Elapsed: 141.24432349205017 |
                      Train | Accuracy: 0.8812 | Loss: 0.3333
                 Validation | Accuracy: 0.6093 | Loss: 1.4620

--------------------
Epoch 16 / 50
--------------------
Learning Rate: 7.938926261462366e-05
Epoch 16 | Time Elapsed: 143.10353446006775 |
                      Train | Accuracy: 0.8938 | Loss: 0.2964
                 Validation | Accuracy: 0.6196 | Loss: 1.4973

--------------------
Epoch 17 / 50
--------------------
Learning Rate: 7.679133974894982e-05
Epoch 17 | Time Elapsed: 141.88441562652588 |
                      Train | Accuracy: 0.9071 | Loss: 0.2651
                 Validation | Accuracy: 0.6218 | Loss: 1.5741

--------------------
Epoch 18 / 50
--------------------
Learning Rate: 7.408768370508575e-05
Epoch 18 | Time Elapsed: 142.3323621749878 |
                      Train | Accuracy: 0.9161 | Loss: 0.2369
                 Validation | Accuracy: 0.6194 | Loss: 1.6431

--------------------
Epoch 19 / 50
--------------------
Learning Rate: 7.128896457825361e-05
Epoch 19 | Time Elapsed: 142.06033086776733 |
                      Train | Accuracy: 0.9213 | Loss: 0.2169
                 Validation | Accuracy: 0.6120 | Loss: 1.7232

--------------------
Epoch 20 / 50
--------------------
Learning Rate: 6.840622763423389e-05
Epoch 20 | Time Elapsed: 140.41664242744446 |
                      Train | Accuracy: 0.9299 | Loss: 0.1954
                 Validation | Accuracy: 0.6205 | Loss: 1.7590

--------------------
Epoch 21 / 50
--------------------
Learning Rate: 6.545084971874736e-05
Epoch 21 | Time Elapsed: 142.4247109889984 |
                      Train | Accuracy: 0.9405 | Loss: 0.1700
                 Validation | Accuracy: 0.6205 | Loss: 1.8782

--------------------
Epoch 22 / 50
--------------------
Learning Rate: 6.243449435824272e-05
Epoch 22 | Time Elapsed: 141.49664664268494 |
                      Train | Accuracy: 0.9452 | Loss: 0.1564
                 Validation | Accuracy: 0.6171 | Loss: 1.8971

--------------------
Epoch 23 / 50
--------------------
Learning Rate: 5.9369065729286224e-05
Epoch 23 | Time Elapsed: 141.18269085884094 |
                      Train | Accuracy: 0.9502 | Loss: 0.1386
                 Validation | Accuracy: 0.6168 | Loss: 1.9287

--------------------
Epoch 24 / 50
--------------------
Learning Rate: 5.626666167821521e-05
Epoch 24 | Time Elapsed: 141.78448390960693 |
                      Train | Accuracy: 0.9550 | Loss: 0.1288
                 Validation | Accuracy: 0.6178 | Loss: 2.0381

--------------------
Epoch 25 / 50
--------------------
Learning Rate: 5.3139525976465657e-05
Epoch 25 | Time Elapsed: 141.01990842819214 |
                      Train | Accuracy: 0.9617 | Loss: 0.1086
                 Validation | Accuracy: 0.6181 | Loss: 2.1136

--------------------
Epoch 26 / 50
--------------------
Learning Rate: 4.999999999999998e-05
Epoch 26 | Time Elapsed: 141.58115029335022 |
                      Train | Accuracy: 0.9655 | Loss: 0.0992
                 Validation | Accuracy: 0.6184 | Loss: 2.1401

--------------------
Epoch 27 / 50
--------------------
Learning Rate: 4.6860474023534314e-05
Epoch 27 | Time Elapsed: 140.8662552833557 |
                      Train | Accuracy: 0.9689 | Loss: 0.0871
                 Validation | Accuracy: 0.6188 | Loss: 2.1445

--------------------
Epoch 28 / 50
--------------------
Learning Rate: 4.3733338321784775e-05
Epoch 28 | Time Elapsed: 140.423109292984 |
                      Train | Accuracy: 0.9732 | Loss: 0.0772
                 Validation | Accuracy: 0.6222 | Loss: 2.2563

--------------------
Epoch 29 / 50
--------------------
Learning Rate: 4.063093427071375e-05
Epoch 29 | Time Elapsed: 142.12088680267334 |
                      Train | Accuracy: 0.9775 | Loss: 0.0653
                 Validation | Accuracy: 0.6228 | Loss: 2.3013

--------------------
Epoch 30 / 50
--------------------
Learning Rate: 3.756550564175724e-05
Epoch 30 | Time Elapsed: 140.18375992774963 |
                      Train | Accuracy: 0.9798 | Loss: 0.0587
                 Validation | Accuracy: 0.6251 | Loss: 2.3123
Early Stopping...
Best IoU score: None
--------------------
Test Loss 1.106116128718853
Test Accuracy 0.6321
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 32768/170498071 [00:00<16:28, 172381.77it/s]  0%|          | 65536/170498071 [00:00<16:32, 171737.35it/s]  0%|          | 98304/170498071 [00:00<16:32, 171727.33it/s]  0%|          | 229376/170498071 [00:00<07:36, 372733.18it/s]  0%|          | 458752/170498071 [00:00<04:14, 667256.11it/s]  1%|          | 917504/170498071 [00:01<02:15, 1252826.32it/s]  1%|          | 1835008/170498071 [00:01<01:09, 2417881.00it/s]  2%|▏         | 3702784/170498071 [00:01<00:35, 4754929.14it/s]  4%|▍         | 6455296/170498071 [00:01<00:21, 7706232.19it/s]  6%|▌         | 9437184/170498071 [00:01<00:15, 10073350.33it/s]  7%|▋         | 12550144/170498071 [00:02<00:13, 11884705.07it/s]  9%|▉         | 15564800/170498071 [00:02<00:11, 12994899.23it/s] 11%|█         | 18579456/170498071 [00:02<00:11, 13759618.60it/s] 13%|█▎        | 21626880/170498071 [00:02<00:10, 14335726.12it/s] 14%|█▍        | 24641536/170498071 [00:02<00:09, 14690465.83it/s] 16%|█▌        | 27688960/170498071 [00:03<00:09, 14983469.83it/s] 18%|█▊        | 30736384/170498071 [00:03<00:09, 15187500.71it/s] 20%|█▉        | 33652736/170498071 [00:03<00:09, 15142138.74it/s] 21%|██▏       | 36569088/170498071 [00:03<00:08, 15106290.22it/s] 23%|██▎       | 39583744/170498071 [00:03<00:08, 15204621.86it/s] 25%|██▍       | 42565632/170498071 [00:04<00:08, 15236009.40it/s] 27%|██▋       | 45481984/170498071 [00:04<00:08, 15179042.51it/s] 28%|██▊       | 48496640/170498071 [00:04<00:07, 15263695.76it/s] 30%|███       | 51544064/170498071 [00:04<00:07, 15373292.19it/s] 32%|███▏      | 54657024/170498071 [00:04<00:07, 15536530.18it/s] 34%|███▍      | 57671680/170498071 [00:05<00:07, 15524874.39it/s] 36%|███▌      | 60784640/170498071 [00:05<00:07, 15632875.36it/s] 37%|███▋      | 63864832/170498071 [00:05<00:06, 15674703.13it/s] 39%|███▉      | 66912256/170498071 [00:05<00:06, 15671263.59it/s] 41%|████      | 70025216/170498071 [00:05<00:06, 15841005.04it/s] 43%|████▎     | 73138176/170498071 [00:06<00:06, 15740184.37it/s] 45%|████▍     | 76283904/170498071 [00:06<00:05, 15849141.43it/s] 47%|████▋     | 79396864/170498071 [00:06<00:05, 16054714.91it/s] 48%|████▊     | 82542592/170498071 [00:06<00:05, 15882132.88it/s] 50%|█████     | 85655552/170498071 [00:06<00:05, 15995475.30it/s] 52%|█████▏    | 88768512/170498071 [00:06<00:05, 15882329.25it/s] 54%|█████▍    | 91881472/170498071 [00:07<00:04, 15906810.40it/s] 56%|█████▌    | 94994432/170498071 [00:07<00:04, 15927243.80it/s] 58%|█████▊    | 98041856/170498071 [00:07<00:04, 15845835.43it/s] 59%|█████▉    | 101122048/170498071 [00:07<00:04, 15824362.99it/s] 61%|██████    | 104169472/170498071 [00:07<00:04, 15755543.41it/s] 63%|██████▎   | 107249664/170498071 [00:08<00:04, 15744153.42it/s] 65%|██████▍   | 110395392/170498071 [00:08<00:03, 15834862.20it/s] 67%|██████▋   | 113410048/170498071 [00:08<00:03, 15720702.87it/s] 68%|██████▊   | 116457472/170498071 [00:08<00:03, 15676402.25it/s] 70%|███████   | 119472128/170498071 [00:08<00:03, 15600955.03it/s] 72%|███████▏  | 122585088/170498071 [00:09<00:03, 15703997.25it/s] 74%|███████▎  | 125665280/170498071 [00:09<00:02, 15733369.28it/s] 76%|███████▌  | 128745472/170498071 [00:09<00:02, 15752132.88it/s] 77%|███████▋  | 131891200/170498071 [00:09<00:02, 15900925.62it/s] 79%|███████▉  | 134873088/170498071 [00:09<00:02, 15605997.18it/s] 81%|████████  | 137756672/170498071 [00:10<00:02, 15340675.83it/s] 83%|████████▎ | 140673024/170498071 [00:10<00:01, 15162401.15it/s] 84%|████████▍ | 143589376/170498071 [00:10<00:01, 15051969.22it/s] 86%|████████▌ | 146538496/170498071 [00:10<00:01, 14977799.76it/s] 88%|████████▊ | 149454848/170498071 [00:10<00:01, 14928608.79it/s] 89%|████████▉ | 152338432/170498071 [00:11<00:01, 14838853.20it/s] 91%|█████████ | 155254784/170498071 [00:11<00:01, 14835901.62it/s] 93%|█████████▎| 158236672/170498071 [00:11<00:00, 14954118.92it/s] 94%|█████████▍| 161087488/170498071 [00:11<00:00, 14870442.61it/s] 96%|█████████▌| 164036608/170498071 [00:11<00:00, 14897289.80it/s] 98%|█████████▊| 167084032/170498071 [00:12<00:00, 14960028.04it/s]100%|█████████▉| 169934848/170498071 [00:12<00:00, 14899077.58it/s]100%|██████████| 170498071/170498071 [00:12<00:00, 13871379.19it/s]
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 32768/170498071 [00:00<16:38, 170795.91it/s]  0%|          | 65536/170498071 [00:00<16:36, 171048.73it/s]  0%|          | 98304/170498071 [00:00<16:35, 171216.73it/s]  0%|          | 229376/170498071 [00:00<07:35, 373438.64it/s]  0%|          | 458752/170498071 [00:00<04:13, 670167.94it/s]  1%|          | 917504/170498071 [00:01<02:14, 1256342.14it/s]  1%|          | 1835008/170498071 [00:01<01:09, 2410737.04it/s]  2%|▏         | 3702784/170498071 [00:01<00:35, 4742279.52it/s]  4%|▍         | 6815744/170498071 [00:01<00:19, 8341004.46it/s]  6%|▌         | 9961472/170498071 [00:01<00:14, 10810347.17it/s]  8%|▊         | 13074432/170498071 [00:02<00:12, 12489526.93it/s] 10%|▉         | 16220160/170498071 [00:02<00:11, 13643677.87it/s] 11%|█▏        | 19365888/170498071 [00:02<00:10, 14444129.28it/s] 13%|█▎        | 22478848/170498071 [00:02<00:09, 15029059.49it/s] 15%|█▌        | 25591808/170498071 [00:02<00:09, 15432502.92it/s] 17%|█▋        | 28737536/170498071 [00:03<00:09, 15655118.22it/s] 19%|█▊        | 31850496/170498071 [00:03<00:08, 15857563.10it/s] 21%|██        | 34996224/170498071 [00:03<00:08, 15960966.67it/s] 22%|██▏       | 38109184/170498071 [00:03<00:08, 16117867.36it/s] 24%|██▍       | 41254912/170498071 [00:03<00:08, 16133292.48it/s] 26%|██▌       | 44367872/170498071 [00:04<00:07, 16264199.67it/s] 28%|██▊       | 47513600/170498071 [00:04<00:07, 15910020.86it/s] 30%|██▉       | 50626560/170498071 [00:04<00:07, 16402245.28it/s] 31%|███▏      | 53608448/170498071 [00:04<00:06, 18864843.20it/s] 33%|███▎      | 55672832/170498071 [00:04<00:06, 16418796.50it/s] 34%|███▎      | 57475072/170498071 [00:04<00:07, 14450541.05it/s] 35%|███▌      | 59867136/170498071 [00:04<00:06, 15919814.56it/s] 36%|███▋      | 61997056/170498071 [00:05<00:06, 17085027.77it/s] 37%|███▋      | 63864832/170498071 [00:05<00:07, 14682542.14it/s] 39%|███▊      | 66027520/170498071 [00:05<00:06, 16126493.43it/s] 40%|███▉      | 67796992/170498071 [00:05<00:06, 16450913.06it/s] 41%|████      | 69566464/170498071 [00:05<00:07, 14128329.77it/s] 42%|████▏     | 72253440/170498071 [00:05<00:05, 16794625.82it/s] 43%|████▎     | 74088448/170498071 [00:05<00:05, 16772879.15it/s] 45%|████▍     | 75890688/170498071 [00:06<00:06, 14110441.62it/s] 46%|████▌     | 78577664/170498071 [00:06<00:05, 16836480.51it/s] 47%|████▋     | 80445440/170498071 [00:06<00:05, 17074886.72it/s] 48%|████▊     | 82280448/170498071 [00:06<00:06, 14394021.66it/s] 50%|████▉     | 84869120/170498071 [00:06<00:05, 16612052.63it/s] 51%|█████     | 86704128/170498071 [00:06<00:04, 17030085.29it/s] 52%|█████▏    | 88539136/170498071 [00:06<00:05, 14427272.36it/s] 53%|█████▎    | 91095040/170498071 [00:06<00:04, 16782811.87it/s] 55%|█████▍    | 92930048/170498071 [00:07<00:04, 16950579.62it/s] 56%|█████▌    | 94732288/170498071 [00:07<00:05, 14295749.77it/s] 57%|█████▋    | 97353728/170498071 [00:07<00:04, 17086282.03it/s] 58%|█████▊    | 99254272/170498071 [00:07<00:04, 17054641.46it/s] 59%|█████▉    | 101089280/170498071 [00:07<00:04, 14431750.46it/s] 61%|██████    | 103710720/170498071 [00:07<00:04, 14178090.07it/s] 63%|██████▎   | 106790912/170498071 [00:07<00:04, 14747358.88it/s] 64%|██████▍   | 109903872/170498071 [00:08<00:03, 15251141.03it/s] 66%|██████▋   | 113049600/170498071 [00:08<00:03, 15428630.28it/s] 68%|██████▊   | 116162560/170498071 [00:08<00:03, 15532565.09it/s] 70%|██████▉   | 119275520/170498071 [00:08<00:03, 15758218.07it/s] 72%|███████▏  | 122388480/170498071 [00:08<00:03, 15915213.33it/s] 74%|███████▎  | 125534208/170498071 [00:09<00:02, 16050528.57it/s] 75%|███████▌  | 128417792/170498071 [00:09<00:02, 15783725.74it/s] 77%|███████▋  | 131563520/170498071 [00:09<00:02, 15966313.53it/s] 79%|███████▉  | 134709248/170498071 [00:09<00:02, 16095345.16it/s] 81%|████████  | 137822208/170498071 [00:09<00:02, 16153017.90it/s] 83%|████████▎ | 140967936/170498071 [00:10<00:01, 16210525.90it/s] 85%|████████▍ | 144080896/170498071 [00:10<00:01, 16234581.02it/s] 86%|████████▋ | 147226624/170498071 [00:10<00:01, 16272133.10it/s] 88%|████████▊ | 150339584/170498071 [00:10<00:01, 16301495.79it/s] 90%|█████████ | 153485312/170498071 [00:10<00:01, 16249404.88it/s] 92%|█████████▏| 156631040/170498071 [00:11<00:00, 16266555.63it/s] 94%|█████████▎| 159744000/170498071 [00:11<00:00, 16313598.05it/s] 96%|█████████▌| 162856960/170498071 [00:11<00:00, 16438679.91it/s] 97%|█████████▋| 165871616/170498071 [00:11<00:00, 16232867.81it/s] 99%|█████████▉| 168984576/170498071 [00:11<00:00, 16240986.38it/s]100%|██████████| 170498071/170498071 [00:11<00:00, 14305406.66it/s]
